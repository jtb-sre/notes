# Achievements since __2023-06-12__
In order to make performance discussions easier, I've decided to type up a list of achievements since my last review, about when they happened, and what was cool about them.

# Template
## Achievement -- what did I do?
* __When__: Approximate timeframe of when it happened
* __Why__: The "situation" that caused you to solve this problem
* __How__: More details about the technical process, motivation, or the 'action' took to resolve
* __Result__: Quantify benefits to the extent possible

# The List!

## Created CI/CD templates for Maven build
* __When__: August 2023
* __Why__: Team was unfamiliar with CI/CD -- copy & pasting full workflows into all 120 projects which then got out of sync. Done entirely by Shell runner as root, which is a security problem.
* __How__: Created an include-able set of components bundled into a single short file. Taught dev how to modify templates using environment variables and how to modify the code if needed.
* __Result__: Builds standardized, using Docker with a limited-privilege container. Devs able to self serve their CI/CD modifications with the framework in place.

## Automated OS Patching
* __When__: June - September 2023
* __Why__: Linux patching done entirely manually. Took a very long time -- often upwards of 1.5 - 2 hours for a dozen hosts.
* __How__: Created Ansible playbook for automated patching, including startup / shutdown of common applications.
* __Result__: Patching time reduced by 75% (from 2 hours down to 30m)
 
## Created config standards for OS and common applications
* __When__: June - October 2023
* __Why__: Was a need to create 6 new Epic systems.
* __How__: Iterative process with Ansible. Created minimal template, and built VM. Blew the first VM away, and used redeploy to catch issues. A representative population is checked on each commit via CI/CD, and some of my time with new VM deploys is taken up with experimentation and fixes. Apps have documented manual pre & post steps that get whittled down with new deploys.
* __Result__: Time to deploy a new VM went from 1 week down to 4 hours

## Built cross-lab artifact repository for Docker, Maven, and OS repositories
* __When__: July 2023
* __Why__: We didn't have any architecture for package deployment -- code was copied manually onto servers, binaries were held onto in samba shares and scp'ed whe needed. A shell Gitlab-Runner was deployed for CI/CD, but required container rebuilds on every commit and ran as root on a shared host, which is insecure and doesn't allow for multiple concurrent builds.
* __How__: Stood up Nexus artifact repository , built CI/CD templates for our major artifact sources (shell scripts, maven repositories). Created a CI/CD template for building Docker images and created images for common workflows.
* __Result__: Decommed all shell runners, saved existing docker-based workflows up to 5 minutes per run. Opened up new workflows like packaging as OS repo

## Improved lab-wide Restore Preparedness While Reducing Storage Costs
* __When__: July 2023
* __Why__: Backups taking longer & longer for physical hosts that can't take easy advantage of block-level incremental backups. Full backups taking many days to complete. Incremental backups often approaching the size of full backups. Backups only using a single policy -- fulls weekly, cumulative diff daily.
* __How__: Worked with software developers and DBAs to understand their recovery priorities and workflows. Created a few distinct buckets (large files, interconnected files, independent files), and tuned those to improve backup times.
* __Result__: Significant speedup and storage savings for incrementals with no loss in disaster preparedness. Reduced backup injest volume by 30%, saving 50TB of tape space per week

## Worked with Development team to improve logging
* __When__: November 2023
* __Why__: Dev team was logging at a debug-level to syslog, but didn't expect to consume the logs from syslog
* __How__: Identified code paths, wrote up a detailed analysis to developer. When he agreed, I went through the change control process
* __Result__: 12% reduction in Linux log volume with no loss in visibility. Easy to identify errors

## Used networking knowledge to dramatically improve Snort alert accuracy
* __When__: September - November 2023
* __Why__: At peak, Snort generating 850,000 alerts per day. Very hard to find concerning activity, and not especially useful.
* __How__: Generated daily reports of most common alerts, carefully examined to determine legitimate activity. When application behavior was uncertain, worked with application owners to resolve issues or omit from alerts
* __Result__: Alerts per day reduced from 850,000 to 9,000 . Several issues resolved, including an instrument with broken cloud functionality and a service unexpectly running an old & vulnerable Java version
